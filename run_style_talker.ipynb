{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57f1e1ee",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import torch\n",
    "\n",
    "from IPython.display import Audio\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "torch.manual_seed(1234)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5895d8ef",
   "metadata": {},
   "source": [
    "## Set Global Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76410c20",
   "metadata": {},
   "outputs": [],
   "source": [
    "device='cuda' if torch.cuda.is_available() else 'cpu'\n",
    "# device='mps' if torch.backends.mps.is_available() else 'cpu'\n",
    "\n",
    "print(\"Cuda available: \", torch.cuda.is_available())\n",
    "print(\"MPS available: \", torch.backends.mps.is_available())\n",
    "print(\"Using device: \", device)\n",
    "\n",
    "# TTS Paths\n",
    "STYLETTS2_CODE_ROOT = '/Users/pn/dev/avtar/other/StyleTTS2' # where StyleTTS2 repo was cloned to\n",
    "STYLETTS2_CKPT_ROOT = '/Users/pn/dev/avtar/other/Style-Talker/models/styletts2/epoch_2nd_00038.pth'\n",
    "ESPEAK_PATH = '/opt/homebrew/Cellar/espeak/1.48.04_1/lib/libespeak.1.1.48.dylib' # None\n",
    "\n",
    "# Audio LLM's Paths\n",
    "QWENAUDIO_CKPT_ROOT = '/Users/pn/dev/avtar/other/Style-Talker/models/qwenaudio/r16_lr1e-4_ga8_ls1_ep20/checkpoint-44820'\n",
    "# '/engram/naplab/projects/StyleTalker/QwenCkpts/DT_styletalker_ep100_cos/checkpoint-28000'\n",
    "\n",
    "# Locate StyleTTS2's repository\n",
    "if str(STYLETTS2_CODE_ROOT) not in sys.path:\n",
    "    sys.path.append(str(STYLETTS2_CODE_ROOT))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dadfc569",
   "metadata": {},
   "source": [
    "## Load Style-Talker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38babbb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from inference.styletalker import StyleTalker\n",
    "\n",
    "styletalker = StyleTalker(\n",
    "    tts_ckpt_root=STYLETTS2_CKPT_ROOT,\n",
    "    audiollm_ckpt_root=QWENAUDIO_CKPT_ROOT,\n",
    "    tts_code_root=STYLETTS2_CODE_ROOT,\n",
    "    audiollm_kwargs={\n",
    "        'bf16': True,\n",
    "        'lora_r': 16,\n",
    "        'lora_modules': ['c_attn', 'attn.c_proj', 'w1', 'w2', 'query', 'key', 'value'],\n",
    "    },\n",
    "    asr_model=None, # 'openai/whisper-large-v3',\n",
    "    espeak_path=ESPEAK_PATH,\n",
    "    device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd2baea8",
   "metadata": {},
   "source": [
    "## Inference with history texts and styles pre-computed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cf09325",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 0 # conversation index\n",
    "i = 3 # round index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9be55e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_inputs = {\n",
    "    'latest_speech': f'samples/dailytalk/{n}/r{i+2}.wav',\n",
    "    'history_texts': [\n",
    "        open(f'samples/dailytalk/{n}/r{i}.txt', 'r').read(),\n",
    "        open(f'samples/dailytalk/{n}/r{i+1}.txt', 'r').read()\n",
    "    ],\n",
    "    'history_styles': [\n",
    "        torch.load(f'samples/dailytalk/{n}/r{i}.pt'),\n",
    "        torch.load(f'samples/dailytalk/{n}/r{i+1}.pt'),\n",
    "    ],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09d9047d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generated = styletalker(**sample_inputs, override_text = \"You know, I appreciate you saying that. I mean, you know, like, I don't know if I'm gonna be doing this for another 10 years or whatever, but I, I really enjoy doing it and I really enjoy the feedback that I get from people. So, you know, if I'm doing it, I'm doing it. And if I'm not doing it, I'm not doing it. But, you know, I'm gonna do it for as long as I can.\")\n",
    "generated = styletalker(**sample_inputs, override_text = \"Oh, my goodness. I mean, it's been a whole new world of, of, of things. Um, but I would say the most mischievous thing they've done, I think, is that they've learned how to get into the trash. So, um, they've been getting into the trash, um, at night. And they, they leave their little paw prints all over the trash and they pull things out and, um-\")\n",
    "wav = generated['audio']\n",
    "text = generated['text']\n",
    "\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f2541e8",
   "metadata": {},
   "source": [
    "### History -3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4185e244",
   "metadata": {},
   "outputs": [],
   "source": [
    "Audio(f'samples/dailytalk/{n}/r{i}.wav')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b555f27",
   "metadata": {},
   "source": [
    "### History -2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2348825e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Audio(f'samples/dailytalk/{n}/r{i+1}.wav')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f84599c",
   "metadata": {},
   "source": [
    "### History -1 (raw speech without transcription)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff4f3d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Audio(f'samples/dailytalk/{n}/r{i+2}.wav')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94faef0b",
   "metadata": {},
   "source": [
    "### Generated follow-up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9be443a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Audio(wav, rate=24000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f51f38da",
   "metadata": {},
   "source": [
    "### Ground-truth follow-up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a887d09f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Audio(f'samples/dailytalk/{n}/r{i+3}.wav')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c61982ff",
   "metadata": {},
   "source": [
    "## Inference with history speeches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28aa2d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from inference.styletalker import StyleTalker\n",
    "\n",
    "styletalker = StyleTalker(\n",
    "    tts_ckpt_root=STYLETTS2_CKPT_ROOT,\n",
    "    audiollm_ckpt_root=QWENAUDIO_CKPT_ROOT,\n",
    "    tts_code_root=STYLETTS2_CODE_ROOT,\n",
    "    audiollm_kwargs={\n",
    "        'bf16': True,\n",
    "        'lora_r': 16,\n",
    "        'lora_modules': ['c_attn', 'attn.c_proj', 'w1', 'w2', 'query', 'key', 'value'],\n",
    "    },\n",
    "    asr_model='openai/whisper-large-v3', # offline asr model\n",
    "    espeak_path=ESPEAK_PATH,\n",
    "    device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5345ed6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 0 # conversation index\n",
    "i = 2 # round index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7ad7543",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_inputs = {\n",
    "    'latest_speech': f'samples/dailytalk/{n}/r{i+2}.wav',\n",
    "    'history_speeches': [\n",
    "        f'samples/dailytalk/{n}/r{i}.wav',\n",
    "        f'samples/dailytalk/{n}/r{i+1}.wav',\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15d79779",
   "metadata": {},
   "source": [
    "### Transcribe and compute styles of history speeches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c067a8e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "history_texts = [\n",
    "    styletalker.transcribe(history_speech)\n",
    "    for history_speech in sample_inputs['history_speeches']\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d17ccb7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "history_styles = [\n",
    "    styletalker.compute_style(history_speech)\n",
    "    for history_speech in sample_inputs['history_speeches']\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09408592",
   "metadata": {},
   "source": [
    "### Or, pass in history_speeches directly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eb2cb1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "generated = styletalker(\"I really like Harry Potter\", **sample_inputs)\n",
    "wav = generated['audio']\n",
    "text = generated['text']\n",
    "\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18168f88",
   "metadata": {},
   "source": [
    "### History -3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "791094b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "Audio(f'samples/dailytalk/{n}/r{i}.wav')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2866715",
   "metadata": {},
   "source": [
    "### History -2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6069a4b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "Audio(f'samples/dailytalk/{n}/r{i+1}.wav')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8555ae97",
   "metadata": {},
   "source": [
    "### History -1 (raw speech without transcription)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "251dcc8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Audio(f'samples/dailytalk/{n}/r{i+2}.wav')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c6e9bb8",
   "metadata": {},
   "source": [
    "### Generated follow-up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6ae4619",
   "metadata": {},
   "outputs": [],
   "source": [
    "Audio(wav, rate=24000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f6b98c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io.wavfile import write\n",
    "\n",
    "sample_rate = 24000\n",
    "filename = \"generated-follow-up.wav\"\n",
    "\n",
    "write(filename, sample_rate, wav)\n",
    "print(f\"Audio saved to {filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48c8ef59-2b21-4705-b264-f68a3a8ffc49",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
