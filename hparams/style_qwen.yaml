### General ###

seed: 1234
__set_seed: !apply:torch.manual_seed [!ref <seed>]
project: StyleTalker
experiment: StyleQwen
save_dir: !ref save/<experiment>/<seed>

#### Data ###

data_root: /engram/naplab/projects/StyleTalker/dailytalk_16k
train_root: !apply:os.path.join [!ref <data_root>, 'train']
valid_root: !apply:os.path.join [!ref <data_root>, 'val']

# The maximum number of audio + text tokens
max_len: 1536
# The maximum number of speaker turns. e.g. 3: 
# spkA -> spkB -> spkA (audio only) -> spkB to predict
max_turn: 3

train_data: !new:data.dataset.StyledConversations
    data_root: !ref <train_root>
    tokenizer: !ref <tokenizer>
    max_len: !ref <max_len>
    max_turn: !ref <max_turn>

valid_data: !new:data.dataset.StyledConversations
    data_root: !ref <valid_root>
    tokenizer: !ref <tokenizer>
    max_len: !ref <max_len>
    max_turn: !ref <max_turn>

### Tokenizer ###

tokenizer: !apply:QwenAudio.prepare_tokenizer.get_tokenizer

in_style_id: !apply:QwenAudio.prepare_tokenizer.get_in_style_id
    tokenizer: !ref <tokenizer>
out_style_id: !apply:QwenAudio.prepare_tokenizer.get_out_style_id
    tokenizer: !ref <tokenizer>

data_collator: !new:data.dataset.DataCollatorStyles
    tokenizer: !ref <tokenizer>

### LoRA ###

rank: 16
alpha: 16
lora_config: !new:peft.LoraConfig
    r: !ref <rank>
    lora_alpha: !ref <alpha>
    target_modules: ['c_attn', 'attn.c_proj', 'w1', 'w2', 'query', 'key', 'value']
    lora_dropout: 0.05
    bias: none

### LLM ###

qwen: !apply:transformers.AutoModelForCausalLM.from_pretrained
    pretrained_model_name_or_path: Qwen/Qwen-Audio-Chat
    device_map: cpu
    bf16: !ref <bf16>
    trust_remote_code: true

lora_qwen: !apply:peft.get_peft_model
    model: !ref <qwen>
    peft_config: !ref <lora_config>

### Style Qwen Audio ###

style_loss_dim: 128

### Training Config ###

bf16: true
optim: adamw_torch
lr: 1.0e-4
batch_size: 1
gradient_accumulation_steps: 8
n_epoch: 20

lambda_style: 1

train_config: !new:transformers.TrainingArguments
    run_name: !ref <experiment>
    output_dir: !ref <save_dir>
    optim: !ref <optim>
    learning_rate: !ref <lr>
    per_device_train_batch_size: !ref <batch_size>
    per_device_eval_batch_size: 1
    dataloader_num_workers: 8
    bf16: !ref <bf16>
    num_train_epochs: !ref <n_epoch>
    save_strategy: epoch
    gradient_accumulation_steps: !ref <gradient_accumulation_steps>
    save_safetensors: false
    save_total_limit: 3
    load_best_model_at_end: false
    remove_unused_columns: false
    logging_steps: 100
    report_to: !ref <report_to>

### wandb ###

report_to: wandb
